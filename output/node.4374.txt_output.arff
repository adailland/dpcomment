% Generated by Discussion model node.4374.txt
% File generated on 2017/08/09 19:32:23

@relation pr1502321543985

@attribute author String
@attribute textual String
@attribute isProjectMember {TRUE, FALSE}
@attribute isInvited {TRUE, FALSE}
@attribute numberOfWords numeric
@attribute commentsSoFar numeric
@attribute allUtterancesSoFar numeric
@attribute utterancesInCommentSoFar numeric
@attribute utteredByOriginalPoster {TRUE, FALSE}
@attribute hasCapitalizedWord {TRUE, FALSE}
@attribute containsShould {TRUE, FALSE}
@attribute hasDecisions {TRUE, FALSE}
@attribute howManyDecisions numeric
@attribute idComment numeric
@attribute idPara numeric

@data
mcollina,"This PR adds support for:",FALSE,FALSE,5,0,0,0,TRUE,TRUE,FALSE,TRUE,0,1,1
mcollina,"socket.send(buf, port, host, [, callback])",FALSE,FALSE,5,0,1,1,TRUE,FALSE,FALSE,TRUE,0,1,2
mcollina,"socket.send([buf1, buf2, ... ], port, host, [, callback])",FALSE,FALSE,8,0,2,2,TRUE,FALSE,FALSE,TRUE,0,1,3
mcollina,"Fixes #4302.",FALSE,FALSE,2,0,3,3,TRUE,FALSE,FALSE,TRUE,0,1,4
mcollina,"This is probably missing some benchmarks, and might like an optimization pass, but I would like to get some feedbacks first :).",FALSE,FALSE,22,0,4,4,TRUE,TRUE,FALSE,TRUE,0,1,5
mcollina,"cc @ronkorving @indutny @saghul",FALSE,FALSE,4,0,5,5,TRUE,FALSE,FALSE,TRUE,0,1,6
indutny,"I guess arguments fit on the same line? ;)",FALSE,TRUE,9,1,6,0,FALSE,TRUE,FALSE,TRUE,0,2,1
indutny,"[ buffer ]",FALSE,TRUE,3,2,7,0,FALSE,FALSE,FALSE,TRUE,0,3,1
indutny,"What should we do about encoding?",FALSE,TRUE,6,3,9,1,FALSE,TRUE,TRUE,TRUE,0,4,1
indutny,"Did we actually support strings here?",FALSE,TRUE,6,4,11,1,FALSE,TRUE,FALSE,TRUE,0,5,1
indutny,"I think we didn't, I would not introduce APIs that convert strings to Buffers without using encoding. This seems to be inconsistent with the rest of the core.",FALSE,TRUE,28,5,13,1,FALSE,TRUE,FALSE,TRUE,0,6,1
mcollina,"dgram supports strings without encoding at this point. I'm up for supporting only Buffers in this new API.Strings without encoding are just  bad .",FALSE,FALSE,23,6,15,1,TRUE,TRUE,FALSE,TRUE,0,7,1
mcollina,"Original: https://github.com/nodejs/node/blob/master/lib/dgram.js#L253-L254",FALSE,FALSE,2,6,16,2,TRUE,FALSE,FALSE,TRUE,0,7,2
indutny,"Ah, I see it now. Yeah, this is weird, but I agree that we may fix it later.",FALSE,TRUE,18,7,17,0,FALSE,TRUE,FALSE,TRUE,0,8,1
mcollina,"Given that this API signature is new, I would fix it now if possible.",FALSE,FALSE,14,8,18,0,TRUE,TRUE,FALSE,TRUE,0,9,1
mcollina,"I'm ðŸ‘? to support only buffers in the 4 parameters send (the new one).Any other opinions?",FALSE,FALSE,16,8,20,2,TRUE,TRUE,FALSE,TRUE,0,9,2
indutny,"Please put it on the same line, it is going to fit here now.",FALSE,TRUE,14,9,21,0,FALSE,TRUE,FALSE,TRUE,0,10,1
indutny,"I feel like it could be potentially slower and will do excessive allocation. Perhaps we should just pass offset to the C++ layer?",FALSE,TRUE,23,10,23,1,FALSE,TRUE,TRUE,TRUE,0,11,1
mcollina,"I agree, that was done before and I cut it from here to get some feedback. However, I am struggling a bit to support both APIs through the same C++ function.Should I (partially) duplicate that, or should I use positional argument in the array for offset and length for each buffer?Or should I allocate a new object for each of this? You probably have some idea of what will behave better.",FALSE,FALSE,71,11,26,2,TRUE,TRUE,TRUE,TRUE,0,12,1
mcollina,"Basically I can pass [buf1, offset1, length1, buf2, offset2, length2, ...].",FALSE,FALSE,11,11,27,3,TRUE,TRUE,FALSE,TRUE,0,12,2
mcollina,"However I am not entirely sure this is worth the effort, but me and @mscdex disagree on this: #4302 (comment) #4302 (comment)",FALSE,FALSE,22,11,28,4,TRUE,TRUE,FALSE,TRUE,0,12,3
ronkorving,"If you're gonna send an array of buffers, I have no idea what the point of offset and length should be. It seems a rather useless feature (hence my initial proposal for a method called sendv instead). I honestly have no opinion as to what the semantics here should be, but if you can find any that make any sense at all, go for it. I don't think unix's sendmsg function actually takes these arguments when sending msg_iov.",FALSE,TRUE,78,12,30,1,FALSE,TRUE,TRUE,TRUE,0,13,1
ronkorving,"Now as far the  old  case when sending a single buffer, I don't think it should be incurring a slice penalty. Especially since in many calls offset will be 0, and length will be the total length anyway (those cases should be optimized out). The fact is though, that libuv only really seems to support sendmsg with a message object, and not a call with offset and length. The fact that Node exposes these may be legacy reasons (I don't know the history of it but can imagine that before libuv the sendmsg syscall was used differently).",FALSE,TRUE,97,12,32,3,FALSE,TRUE,TRUE,TRUE,0,13,2
ronkorving,"So long story short: using offset and length with an array of buffers is a weird pattern, but some semantics need to be found (eg: slicing while considering offset to apply to the first buffer(s), and length to apply to the buffers' collective size) and building a new array could do the trick). When sending a non-array however, cost should be no greater than it used to be.",FALSE,TRUE,68,12,34,5,FALSE,TRUE,TRUE,TRUE,0,13,3
mcollina,"If you're gonna send an array of buffers, I have no idea what the point of offset and length should be. It seems a rather useless feature (hence my initial proposal for a method called sendv instead). I honestly have no opinion as to what the semantics here should be, but if you can find any that make any sense at all, go for it. I don't think unix's sendmsg function actually takes these arguments when sending msg_iov.",FALSE,FALSE,78,13,35,0,TRUE,TRUE,TRUE,TRUE,0,14,1
mcollina,"I would really try to avoid code duplication for both cases, as I would not like to maintain both a 'send' and 'sendv' in C++ land. This is basically why I am asking this question. This is only relevant to the internal C++ API, not to the user-facing API, which would just be an array of buffers.",FALSE,FALSE,57,13,37,2,TRUE,TRUE,FALSE,TRUE,0,14,2
mcollina,"The fact is though, that libuv only really seems to support sendmsg with a message object, and not a call with offset and length. The fact that Node exposes these may be legacy reasons (I don't know the history of it but can imagine that before libuv the sendmsg syscall was used differently).",FALSE,FALSE,53,13,38,3,TRUE,TRUE,FALSE,TRUE,0,14,3
mcollina,"This is not correct. The point where we are currently using offset and length in C++ is: https://github.com/nodejs/node/blob/master/src/udp_wrap.cc#L267-L268. That structure that goes deep down into sendmsg, and it is where the magic happens. This is faster than slicing in JS land, however I have no idea how faster it is.",FALSE,FALSE,50,13,40,5,TRUE,TRUE,FALSE,TRUE,0,14,4
mcollina,"IMHO, having offset and length are kind of useless anyway because of UDP. Does anybody has a lib that is using those heavily to test it?",FALSE,FALSE,26,13,42,7,TRUE,TRUE,FALSE,TRUE,0,14,5
indutny,"We have similar APIs in fs module as well. I think I agree with using slice here, the whole API seems to be not that necessary, and I doubt that it is used that much. Thanks!",FALSE,TRUE,36,14,44,1,FALSE,TRUE,FALSE,TRUE,0,15,1
ronkorving,"Great start, thanks a ton :) What do the benchmarks say at this time?",FALSE,TRUE,14,15,45,0,FALSE,TRUE,FALSE,TRUE,0,16,1
mcollina,"Current benchmarks comes out slightly slower on the  old  API. These are possibly due to: #4374 (diff)",FALSE,FALSE,17,16,46,0,TRUE,TRUE,FALSE,TRUE,0,17,1
mcollina,"before:net/dgram.js len=1 num=100 type=send dur=5: 0.00120net/dgram.js len=1 num=100 type=recv dur=5: 0.00020net/dgram.js len=64 num=100 type=send dur=5: 0.07730net/dgram.js len=64 num=100 type=recv dur=5: 0.01255net/dgram.js len=256 num=100 type=send dur=5: 0.30837net/dgram.js len=256 num=100 type=recv dur=5: 0.04958net/dgram.js len=1024 num=100 type=send dur=5: 0.71537net/dgram.js len=1024 num=100 type=recv dur=5: 0.12022",FALSE,FALSE,41,16,47,1,TRUE,FALSE,FALSE,TRUE,0,17,2
mcollina,"After:net/dgram.js len=1 num=100 type=send dur=5: 0.00106net/dgram.js len=1 num=100 type=recv dur=5: 0.00018net/dgram.js len=64 num=100 type=send dur=5: 0.06785net/dgram.js len=64 num=100 type=recv dur=5: 0.01109net/dgram.js len=256 num=100 type=send dur=5: 0.27151net/dgram.js len=256 num=100 type=recv dur=5: 0.04330net/dgram.js len=1024 num=100 type=send dur=5: 0.70451net/dgram.js len=1024 num=100 type=recv dur=5: 0.11787",FALSE,FALSE,41,16,48,2,TRUE,FALSE,FALSE,TRUE,0,17,3
mcollina,"I have no benchmarks yet on the new APIs.",FALSE,FALSE,9,16,49,3,TRUE,TRUE,FALSE,TRUE,0,17,4
thefourtheye,"Use common.mustCall here, so that it will make sure that the test will fail if the callback is not invoked.",FALSE,FALSE,20,17,51,1,FALSE,TRUE,FALSE,TRUE,0,18,1
thefourtheye,"Why do we need this? We have few test boxes which run very slowly compared to the others. So, this 200 might not work well with all of them.",FALSE,FALSE,29,18,53,1,FALSE,TRUE,FALSE,TRUE,0,19,1
mcollina,"I copied it over from the other dgram tests (the same applies to common.mustCall).The whole purpose it making sure that the callback is called within a definite timeframe. We can move this to 1 or 2 seconds without issues.",FALSE,FALSE,39,19,55,1,TRUE,TRUE,FALSE,TRUE,0,20,1
mcollina,"Should I submit a different PR for some test cleanup for all of dgram tests?",FALSE,FALSE,15,19,56,2,TRUE,TRUE,FALSE,TRUE,0,20,2
thefourtheye,"@mcollina I think you should use common.platformTimeout here.",FALSE,FALSE,8,20,58,1,FALSE,TRUE,TRUE,TRUE,0,21,1
mcollina,"Great @thefourtheye, should I amend the other tests as well?",FALSE,TRUE,10,21,60,1,TRUE,TRUE,TRUE,TRUE,0,22,1
thefourtheye,"I am actually not sure why these tests are time-bound.",FALSE,TRUE,10,22,62,1,FALSE,TRUE,FALSE,TRUE,0,23,1
thefourtheye,"Don't use the IP address as it is. Use common.localhostIPv4",FALSE,TRUE,10,23,64,1,FALSE,TRUE,FALSE,TRUE,0,24,1
mcollina,"should I amend the other tests as well? All the dgram tests follows the same convention.",FALSE,TRUE,16,24,66,1,TRUE,TRUE,TRUE,TRUE,0,25,1
thefourtheye,"Yes. We should avoid using the hardcoded IPs unless absolutely necessary.",FALSE,TRUE,11,25,68,1,FALSE,TRUE,TRUE,TRUE,0,26,1
mcollina,"@thefourtheye @indutny I have updated the tests to follow the current conventions. I will update also the other test to the same on another PR.",FALSE,TRUE,25,29,72,0,TRUE,TRUE,FALSE,TRUE,0,30,1
saghul,"Not on this PR, but it would probably be nice to use uv_udp_try_send here, just in case we can send it on the spot.",FALSE,TRUE,24,30,74,1,FALSE,TRUE,FALSE,TRUE,0,31,1
mcollina,"I would do that after this land. Do you see any issue with switching to uv_udp_try_send?What is the difference anyway? on what conditions it can be sent on the spot?",FALSE,TRUE,30,31,77,2,TRUE,TRUE,FALSE,TRUE,0,32,1
saghul,"It's not switching, the idea is to use it to try to send the datagram on the spot, because the socket might be writable. Have a look at how uv_try_write is used in stream_wrap.cc.",FALSE,TRUE,34,32,79,1,FALSE,TRUE,FALSE,TRUE,0,33,1
mcollina,"I'm ðŸ‘? on that. I'll get it done after this one.",FALSE,TRUE,11,33,80,0,TRUE,TRUE,FALSE,TRUE,0,34,1
thefourtheye,"Better run all these in strict mode",FALSE,TRUE,7,34,82,1,FALSE,TRUE,FALSE,TRUE,0,35,1
mcollina,"I have done a pass of performance optimization in JS-land, which result in better performance for the single buffer use case (and offset/length is now on par with master).",FALSE,TRUE,29,35,83,0,TRUE,TRUE,FALSE,TRUE,0,36,1
mcollina,"Here are the full results:https://gist.github.com/mcollina/e8210d26ca6ef2630e23",FALSE,TRUE,5,35,84,1,TRUE,FALSE,FALSE,TRUE,0,36,2
mcollina,"Unexpectedly, passing multiple buffers in an array is slower (benchmark/dgram/headers.js) than calling Buffer.concat() in js land for a large payload:",FALSE,TRUE,20,35,86,3,TRUE,TRUE,FALSE,TRUE,0,36,3
mcollina,"The small buffer case (up to 256 bytes) is way faster than calling Buffer.concat().",FALSE,TRUE,14,35,87,4,TRUE,TRUE,FALSE,TRUE,0,36,4
mcollina,"Any ideas why this is happening? I expected it to be faster.",FALSE,TRUE,12,35,88,5,TRUE,TRUE,FALSE,TRUE,0,36,5
trevnorris,"nit: function name is slightly incomplete? maybe something like fixAndSumBuffers(). this is nothing serious, and not a blocker.",FALSE,TRUE,18,37,91,1,FALSE,FALSE,FALSE,TRUE,0,38,1
trevnorris,"The only variable I see here that's being used is self. Since 'once' is called on the self object it will also be the this in the callback. So this function can be hoisted.",FALSE,TRUE,34,38,93,1,FALSE,TRUE,FALSE,TRUE,0,39,1
trevnorris,"It's cheaper to check for instanceof Buffer (or HasInstance() from C++) than to always wrap the buffer in an array.",FALSE,TRUE,20,39,95,1,FALSE,TRUE,FALSE,TRUE,0,40,1
mcollina,"I have tried this and it turns out 20% slower on my bench. Would you mind clarifying it a bit better?",FALSE,TRUE,21,40,97,1,TRUE,TRUE,FALSE,TRUE,0,41,1
trevnorris,"naw. don't worry about it now. i'll take a look later. if there were savings they'd be minimal at best.",FALSE,TRUE,20,41,98,0,FALSE,FALSE,FALSE,TRUE,0,42,1
trevnorris,"No need for this. Both Buffer::Length() and Buffer::Data() already have this check.",FALSE,TRUE,12,42,100,1,FALSE,TRUE,FALSE,TRUE,0,43,1
trevnorris,"Since the ||, why not just check if (callback === undefined) and remove the need for arguments?",FALSE,TRUE,17,43,102,1,FALSE,TRUE,FALSE,TRUE,0,44,1
trevnorris,"Optimal case you'd allow the user to pass a string to C++, copy out the memory there and store a pointer to it on the class. Then free the memory in the destructor. This would have to be a linked list, since you're accepting an array of values, but would remove the additional overhead of creating another Buffer object and the GC cost of cleaning it up.",FALSE,TRUE,67,44,104,1,FALSE,TRUE,FALSE,TRUE,0,45,1
mcollina,"Agreed, let's finalize this and then I can submit another PR to handle the strings. However, there is the encoding issue to be solved.",FALSE,TRUE,24,45,105,0,TRUE,TRUE,FALSE,TRUE,0,46,1
trevnorris,"The offset checks here are no longer necessary since we've moved to typed arrays.",FALSE,TRUE,14,46,107,1,FALSE,TRUE,FALSE,TRUE,0,47,1
trevnorris,"Finished quick review.",FALSE,TRUE,3,47,108,0,FALSE,TRUE,FALSE,TRUE,0,48,1
mcollina,"@trevnorris thanks for the feedbacks! I have implemented most of them, and they works :D.",FALSE,TRUE,15,48,109,0,TRUE,TRUE,FALSE,TRUE,0,49,1
mcollina,"However, it does not solve the slowdown when using the multiple buffer API vs using Buffer.concat().If you look at:",FALSE,TRUE,19,48,110,1,TRUE,TRUE,FALSE,TRUE,0,49,2
mcollina,"You'll see that the more elements there are in the array, the slower the array implementation gets vs the Buffer.concat() one.",FALSE,TRUE,21,48,111,2,TRUE,TRUE,FALSE,TRUE,0,49,3
mcollina,"@saghul might be something on libuv side?",FALSE,TRUE,7,48,113,4,TRUE,FALSE,FALSE,TRUE,0,49,4
saghul,"On the libuv layer we use sendmsg regardless of the number of buffers. There is however one small difference: if there are more than 4 buffers we need to malloc an array of uv_buf_t structures (just the structures, not the data).",FALSE,TRUE,41,49,115,1,FALSE,TRUE,FALSE,TRUE,0,50,1
mcollina,"@saghul I've tried increasing that parameter to 16, but things does not change when sending 8 reqs down to libuv.",FALSE,TRUE,20,50,117,1,TRUE,TRUE,FALSE,TRUE,0,51,1
mcollina,"Even removing the fixBuffer loop in js-land does not increase the speed, so it's either something in my bench, or something that is slowing things down in C++/C, or something more weird that I do not understand.",FALSE,TRUE,37,50,118,2,TRUE,TRUE,FALSE,TRUE,0,51,2
mcollina,"As a safety check I'll run my benchmark on Linux (virtualized), just to check if it's a Mac OS X issue.",FALSE,TRUE,21,50,119,3,TRUE,TRUE,FALSE,TRUE,0,51,3
mcollina,"Confirmed, it's a Mac OS X issue. On Linux it is 20% faster to send a list of messages than Buffer.concat(). There should be a sendmsg issue on Mac OS X.",FALSE,TRUE,31,51,121,1,TRUE,TRUE,TRUE,TRUE,0,52,1
mcollina,"@saghul @trevnorris should this be worked around here or in libuv?",FALSE,TRUE,11,51,122,2,TRUE,FALSE,TRUE,TRUE,0,52,2
saghul,"I don't see how, to be honest. There is no extra magic we use.",FALSE,TRUE,14,52,123,0,FALSE,TRUE,FALSE,TRUE,0,53,1
mcollina,"You don't see why this happens, or you don't see how to work around it?",FALSE,TRUE,15,53,124,0,TRUE,TRUE,FALSE,TRUE,0,54,1
mcollina,"Anyway, my proposal is to work around it in JS-land. It is a very bad'fix', but it's quick to implement. A longer term fix is probably to mallocand memcpy all the buffers in libuv.",FALSE,TRUE,34,53,126,2,TRUE,TRUE,FALSE,TRUE,0,54,2
mcollina,"Is it possible that all the sendmsg calls with multiple buffers on OS X areslower, or should it be a udp only thing?",FALSE,TRUE,23,53,128,4,TRUE,TRUE,TRUE,TRUE,0,54,3
trevnorris,"If you take a look at WriteWrap you'll see storage_size_. What this class does is allocate itself + the amount needed for the remaining data to be sent (look at WriteWrap::New() insrc/stream_base-inl.h). Then the data is copied into the extra allocated space. May be of use, but may also be faster to simply keep a reference to all Buffers and create a list of uv_buf_t.",FALSE,TRUE,65,54,130,1,FALSE,TRUE,FALSE,TRUE,0,55,1
saghul,"A longer term fix is probably to malloc and memcpy all the buffers in libuv.",FALSE,TRUE,15,55,131,0,FALSE,TRUE,FALSE,TRUE,0,56,1
saghul,"I don't see this happening. It goes against the core design principles in libuv. We never copy buffers.",FALSE,TRUE,18,55,133,2,FALSE,TRUE,FALSE,TRUE,0,56,2
saghul,"Is it possible that all the sendmsg calls with multiple buffers on OS X are slower, or should it be a udp only thing?",FALSE,TRUE,24,55,134,3,FALSE,TRUE,TRUE,TRUE,0,56,3
saghul,"It could be a kernel thing in OSX, yeah :-S",FALSE,TRUE,10,55,135,4,FALSE,TRUE,FALSE,TRUE,0,56,4
mcollina,"@trevnorris @saghul I'm calling Buffer.concat() in js-land, as it is faster that way for 1024 messages (possibly because the memory was already allocated somewhere else). Passing multiple buffers is 20% faster on Linux and on par on Mac OS X (~10% faster than current implementation, due to other perf fixes).",FALSE,TRUE,50,56,137,1,TRUE,TRUE,FALSE,TRUE,0,57,1
mcollina,"Let me know if you are happy with this, so that I will get the new signatures for send documented.",FALSE,TRUE,20,56,138,2,TRUE,TRUE,FALSE,TRUE,0,57,2
trevnorris,"nit: since neither of these can be < 0, mind doing offset >>> 0 instead?",FALSE,TRUE,15,57,139,0,FALSE,FALSE,FALSE,TRUE,0,58,1
trevnorris,"missing some semicolons. make sure to run lint. :)",FALSE,TRUE,9,58,140,0,FALSE,FALSE,FALSE,TRUE,0,59,1
trevnorris,"style nit: two spaces between functions please.",FALSE,TRUE,7,59,141,0,FALSE,FALSE,FALSE,TRUE,0,60,1
trevnorris,"style nit: use {} on both if and else.",FALSE,TRUE,9,60,142,0,FALSE,FALSE,FALSE,TRUE,0,61,1
trevnorris,"iirc you gave a specific reason why it's slower on os x. mind commenting on that here so future devs know what to look for when checking for the same optimization?",FALSE,TRUE,31,61,144,1,FALSE,FALSE,FALSE,TRUE,0,62,1
trevnorris,"/cc @bnoordhuis have any comments on platform specific optimizations like this?",FALSE,TRUE,11,61,145,2,FALSE,FALSE,FALSE,TRUE,0,62,2
indutny,"Just to place the comment at the right line. I disagree with presence of isDarwin branch here.",FALSE,TRUE,17,62,146,0,FALSE,TRUE,FALSE,TRUE,0,63,1
trevnorris,"@mcollina looking good. left just a few minor comments.",FALSE,TRUE,9,63,147,0,FALSE,FALSE,FALSE,TRUE,0,64,1
ronkorving,"The same style nit as what @trevnorris points out above. The lack of curly braces here makes this block a bit hard to reason about (especially after the throw).",FALSE,TRUE,29,64,148,0,FALSE,TRUE,FALSE,TRUE,0,65,1
ronkorving,"Unused variable?",FALSE,TRUE,2,65,149,0,FALSE,TRUE,FALSE,TRUE,0,66,1
saghul,"I'm not a fan of the if-darwin-this-else-that thing. Have we tested it on all supported platforms? If Apple improves the performance by 500% how would we know? IMHO it's better to let the OS handle it and add a note in the documentation about the fact that in some platforms it might be slower, so users should run their own benchmarks if their application is performance critical.",FALSE,TRUE,67,66,151,1,FALSE,TRUE,TRUE,TRUE,0,67,1
indutny,"I totally agree with @saghul on the OS X.",FALSE,TRUE,9,67,152,0,FALSE,TRUE,FALSE,TRUE,0,68,1
ronkorving,"Me too. Perhaps better to file a bug report with Apple.",FALSE,TRUE,11,68,153,0,FALSE,TRUE,FALSE,TRUE,0,69,1
mcollina,"@saghul I have not tested it on Windows, but I can do it if you want.I wanted to dig more in what the problem is, and it is definitely an OS X thing - I'd guess they are allocating the memory somewhere (at least it shows the same performance pattern when I do the malloc myself).",FALSE,TRUE,56,69,156,2,TRUE,TRUE,FALSE,TRUE,0,70,1
mcollina,"On the other side, I'm fine with leaving without the isDarwin flag and be slower on OS X, or putting it in and be faster. Any strong opinion on keeping the isDarwinÂ flag?",FALSE,TRUE,32,69,158,4,TRUE,TRUE,FALSE,TRUE,0,70,2
mcollina,"Nits fixed, thanks @ronkorving @trevnorris and @indutny for reviewing.",FALSE,TRUE,9,70,159,0,TRUE,TRUE,FALSE,TRUE,0,71,1
mcollina,"Let me know about the isDarwin flag.",FALSE,TRUE,7,70,160,1,TRUE,FALSE,FALSE,TRUE,0,71,2
ronkorving,"I think the past few comments in the main comment thread didn't really support the isDarwin flag. I'm not really in favor. I think Apple needs to fix this, not us. (not saying I'm not sensitive to this issue and what you're trying to achieve, but as @saghul pointed out, we'll never realize it when Apple improves performance).",FALSE,TRUE,58,71,162,1,FALSE,TRUE,FALSE,TRUE,0,72,1
ronkorving,"I would like to ask though, has this been benchmarked on Linux and Windows? Is it really OSX only? Or has that been the only OS tested?",FALSE,TRUE,27,71,164,3,FALSE,TRUE,FALSE,TRUE,0,72,2
mcollina,"@ronkorving the reason why I dig into this rabbit hole was because I could not explain why passing an array was slower on my box (OS X). I have also tested on Linux (virtualized), and passing an array is 20% faster than calling concat(). I have not tested on Windows, should I?",FALSE,TRUE,52,72,166,1,TRUE,TRUE,TRUE,TRUE,0,73,1
mcollina,"There is a nice benchmark so we can test if things improve.",FALSE,TRUE,12,72,167,2,TRUE,FALSE,FALSE,TRUE,0,73,2
mcollina,"Yes, we should probably report this to Apple.",FALSE,TRUE,8,72,168,3,TRUE,TRUE,TRUE,TRUE,0,73,3
saghul,"@saghul I have not tested it on Windows, but I can do it if you want.",FALSE,TRUE,16,73,169,0,FALSE,TRUE,FALSE,TRUE,0,74,1
saghul,"I don't see the need, different Windows versions could yield different results, same goes even for Linux.",FALSE,TRUE,17,73,171,2,FALSE,TRUE,FALSE,TRUE,0,74,2
saghul,"I wanted to dig more in what the problem is, and it is definitely an OS X thing - I'd guess they are allocating the memory somewhere (at least it shows the same performance pattern when I do the malloc myself).",FALSE,TRUE,41,73,172,3,FALSE,TRUE,FALSE,TRUE,0,74,3
saghul,"It could be coincidence.",FALSE,TRUE,4,73,173,4,FALSE,FALSE,FALSE,TRUE,0,74,4
saghul,"On the other side, I'm fine with leaving without the isDarwin flag and be slower on OS X, or putting it in and be faster. Any strong opinion on keeping the isDarwin flag?",FALSE,TRUE,33,73,174,5,FALSE,TRUE,FALSE,TRUE,0,74,5
saghul,"As I mentioned earlier, I'm -1 on the flag.",FALSE,TRUE,9,73,175,6,FALSE,TRUE,FALSE,TRUE,0,74,6
indutny,"@mcollina did I understand you right: it is slower on both linux and os x? Could this slowness be an artifact of benchmarking?",FALSE,TRUE,23,74,177,1,FALSE,TRUE,FALSE,TRUE,0,75,1
mcollina,"No. It is slower only on Mac OS X, and I have not tested on Windows. OnLinux passing multiple bufs is faster than calling Buffer.concat. I did notexpress myself clearly.Il giorno mer 6 gen 2016 alle 20:14 Fedor Indutny notifications@github.comha scritto:",FALSE,TRUE,41,75,178,0,TRUE,TRUE,FALSE,TRUE,0,76,1
mcollina,"@mcollina https://github.com/mcollina did I understand you right: it isslower on both linux and os x? Could this slowness be an artifact ofbenchmarking?",FALSE,TRUE,22,75,179,1,TRUE,TRUE,FALSE,TRUE,0,76,2
mcollina,"â€”Reply to this email directly or view it on GitHub#4374 (comment).",FALSE,TRUE,11,75,180,2,TRUE,TRUE,FALSE,TRUE,0,76,3
mcollina,"I have removed the isDarwin flag and added the docs for this new feature.",FALSE,TRUE,14,76,181,0,TRUE,TRUE,FALSE,TRUE,0,77,1
ronkorving,"Trailing period is missing (wasn't there before either, but makes sense though, no?)",FALSE,TRUE,13,77,182,0,FALSE,TRUE,FALSE,TRUE,0,78,1
reqshark,"indeed that would be appropriate",FALSE,FALSE,5,78,183,0,FALSE,FALSE,FALSE,TRUE,0,79,1
reqshark,"also i would replace the current use of or with a comma like",FALSE,FALSE,13,78,184,1,FALSE,FALSE,FALSE,TRUE,0,79,2
mcollina,"Thanks, updated.",FALSE,TRUE,2,79,185,0,TRUE,TRUE,FALSE,TRUE,0,80,1
indutny,"Why this?",FALSE,TRUE,2,80,186,0,FALSE,TRUE,FALSE,TRUE,0,81,1
mcollina,"Because @trevnorris asked me to #4374 (comment).I'm not sure why the | 0 was there in the first place.",FALSE,TRUE,19,81,187,0,TRUE,TRUE,FALSE,TRUE,0,82,1
indutny,"The thing is that the code below checks port <= 0, which should be transformed to === 0, because >>> 0 always yields non-negative integer.",FALSE,TRUE,25,82,189,1,FALSE,TRUE,TRUE,TRUE,0,83,1
mcollina,"should I update the check below so that port === 0?",FALSE,TRUE,11,83,190,0,TRUE,TRUE,TRUE,TRUE,0,84,1
indutny,"Yeah, I think so. Thank you!",FALSE,TRUE,6,84,191,0,FALSE,TRUE,FALSE,TRUE,0,85,1
ronkorving,"If port is negative, >>> will not yield 0.",FALSE,TRUE,9,85,193,1,FALSE,TRUE,FALSE,TRUE,0,86,1
ronkorving,"Please be careful with this.",FALSE,TRUE,5,85,194,2,FALSE,FALSE,FALSE,TRUE,0,86,2
reqshark,"passing a negative port seems rather unusual",FALSE,FALSE,7,86,196,1,FALSE,FALSE,FALSE,TRUE,0,87,1
mcollina,"@indutny check updated.",FALSE,TRUE,3,87,197,0,TRUE,FALSE,FALSE,TRUE,0,88,1
ronkorving,"@reqshark but that's what the previous code checked for: <= 0",FALSE,TRUE,11,88,199,1,FALSE,FALSE,FALSE,TRUE,0,89,1
reqshark,"@ronkorving, that's right. good thing UDP is a connectionless,  unreliable protocol . so I'm sure any danger of sendto() aiming toward a negative port is mitigated by that fact.",FALSE,TRUE,28,89,201,1,FALSE,TRUE,FALSE,TRUE,0,90,1
mcollina,"Squashed and updated with all the nits. I think this is ready, would you mind passing through it one last time?",FALSE,TRUE,21,90,202,0,TRUE,TRUE,FALSE,TRUE,0,91,1
jasnell,"const here too :-)",FALSE,FALSE,4,92,204,0,FALSE,FALSE,FALSE,TRUE,0,93,1
jasnell,"Overall LGTM. A few minor nits tho... can you please use const for all the require() calls in the benchmark tests :-)",FALSE,FALSE,22,93,206,1,FALSE,TRUE,FALSE,TRUE,0,94,1
mcollina,"@jasnell updated, thanks :D.",FALSE,TRUE,4,94,207,0,TRUE,FALSE,FALSE,TRUE,0,95,1
jasnell,"CI: https://ci.nodejs.org/job/node-test-pull-request/1219/",FALSE,TRUE,2,95,208,0,FALSE,TRUE,FALSE,TRUE,0,96,1
jasnell,"Failures in CI look unrelated. @trevnorris @thefourtheye @saghul ... any further comments on this?",FALSE,TRUE,14,96,209,0,FALSE,TRUE,FALSE,TRUE,0,97,1
saghul,"I noticed one thing while reviewing the C++ side one last time. This PR adds a new parameter to the send callback, with the size of the sent data, see: https://github.com/nodejs/node/pull/4374/files#diff-b62464f44488c6247346b82a87cbd20aR266 and https://github.com/nodejs/node/pull/4374/files#diff-b62464f44488c6247346b82a87cbd20aR360",FALSE,TRUE,33,97,210,0,FALSE,TRUE,FALSE,TRUE,0,98,1
saghul,"Is this an API change we want to make? If so, it's undocumented AFAIS. Since this is UDP, there is no way for that value to be different from the length of the sent buffers, because either the whole datagram goes or doesn't, there is no in between.",FALSE,TRUE,48,97,212,2,FALSE,TRUE,FALSE,TRUE,0,98,2
mcollina,"@saghul no it is not a new parameter, it has been there for a very long time: see https://github.com/nodejs/node/pull/4374/files#diff-5c0ca4f44209cc4cc68c4dccadbd4a07L346.There are also (old) unit tests for this.What did change was that this parameter was kept in JS-land, while now is dealt with in C++ for speed.",FALSE,TRUE,45,98,215,2,TRUE,TRUE,FALSE,TRUE,0,99,1
mcollina,"also cc @mafintosh who has done some UDP work, and might provide some useful feedback.",FALSE,TRUE,15,99,216,0,TRUE,TRUE,FALSE,TRUE,0,100,1
saghul,"@mcollina doh, sorry about that! In my defense, that wan't obvious at all :-)",FALSE,TRUE,14,100,217,0,FALSE,TRUE,FALSE,TRUE,0,101,1
mcollina,"@saghul no worries, it wasn't obvious at all. Good catch anyway, so it remains track of that in here.",FALSE,TRUE,19,102,219,0,TRUE,TRUE,FALSE,TRUE,0,103,1
jasnell,"awesome... I'd still like to have @trevnorris sign off before this lands given his review",FALSE,TRUE,15,103,220,0,FALSE,TRUE,FALSE,TRUE,0,104,1
mcollina,"@jasnell I agree, I have been waiting for some days.",FALSE,TRUE,10,104,221,0,TRUE,TRUE,FALSE,TRUE,0,105,1
mcollina,"What is the process for landing semver-minor into the v5 line? I couldn't really find it.",FALSE,TRUE,16,104,222,1,TRUE,TRUE,FALSE,TRUE,0,105,2
cjihrig,"What is the process for landing semver-minor into the v5 line? I couldn't really find it.",FALSE,FALSE,16,105,223,0,FALSE,TRUE,FALSE,TRUE,0,106,1
cjihrig,"It will land in master. The next time a v5 release is cut, it will be cherry picked over.",FALSE,FALSE,19,105,224,1,FALSE,TRUE,FALSE,TRUE,0,106,2
mafintosh,"@mcollina great to see you working improving dgram a bit :) this would definitely be useful for my utp library as all writes currently require a copy in node to prepend a protocol header. to feature detect for this would i need to check which version of node is running?",FALSE,TRUE,50,106,226,1,FALSE,FALSE,FALSE,TRUE,0,107,1
mcollina,"Unfortunately yes. I think we might write a quick ponyfill to do this wherever it is needed.",FALSE,TRUE,17,107,228,1,TRUE,TRUE,FALSE,TRUE,0,108,1
mcollina,"@trevnorris would you mind having a look at this again, so we can land it?",FALSE,TRUE,15,108,229,0,TRUE,FALSE,FALSE,TRUE,0,109,1
mcollina,"Any other LGTMs, so we can land this?",FALSE,TRUE,8,109,230,0,TRUE,TRUE,FALSE,TRUE,0,110,1
jasnell,"I'd say go for it. CI looked fine after the last run.",FALSE,TRUE,12,110,231,0,FALSE,TRUE,FALSE,TRUE,0,111,1
mcollina,"Giving CI a second run: https://ci.nodejs.org/job/node-test-pull-request/1432/.",FALSE,TRUE,6,111,232,0,TRUE,TRUE,FALSE,TRUE,0,112,1
mcollina,"Landed in 137f53c",FALSE,TRUE,3,112,233,0,TRUE,TRUE,FALSE,TRUE,0,113,1
jasnell,"Thank you!On Jan 29, 2016 10:32 AM,  Matteo Collina  notifications@github.com wrote:",FALSE,TRUE,11,113,234,0,FALSE,TRUE,FALSE,TRUE,0,114,1
jasnell,"Landed in 137f53c137f53c",FALSE,TRUE,3,113,235,1,FALSE,FALSE,FALSE,TRUE,0,114,2
jasnell,"â€”Reply to this email directly or view it on GitHub#4374 (comment).",FALSE,TRUE,11,113,236,2,FALSE,TRUE,FALSE,TRUE,0,114,3
ronkorving,"Great job! Thanks",FALSE,TRUE,3,114,237,0,FALSE,TRUE,FALSE,TRUE,0,115,1
mcollina,"So happy this is released!! Thx to everyone!",FALSE,TRUE,8,115,238,0,TRUE,TRUE,FALSE,TRUE,0,116,1
